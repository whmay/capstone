{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "landmark.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/whmay/capstone/blob/master/landmark.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "i8uMPafTBgXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2315
        },
        "outputId": "c53d1902-504a-451b-bdce-ff2a793b6e27"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmp__10hvao/pubring.gpg' created\n",
            "gpg: /tmp/tmp__10hvao/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19816 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qRCkMZEIJr5R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaMBpCrnJ5go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "10372687-72af-4e91-f42a-d82aa2c87dac"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J_HJrADVKHes",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print('Files in Drive:')\n",
        "!ls drive/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YaYRXskNPcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ae304cf4-2436-48e6-eb9b-dbb834f7fe72"
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install h5py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6t9oDgkMa0T9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install -U --force-reinstall --no-dependencies git+https://github.com/datumbox/keras@bugfix/trainable_bn\n",
        "#http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rHy6IwOiRzOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a786a63-eec3-456a-d495-746be9006488"
      },
      "cell_type": "code",
      "source": [
        "#check whether you are using GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "riZiRc9HRGxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "5eaa658b-25d3-4485-df7b-d4c0407834cc"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/Resnet2\n",
        "!cat drive/Resnet2/labels.txt\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.txt  test  train\n",
            "鸟巢（国家体育场）\n",
            "颐和园\n",
            "雍和宫\n",
            "水立方（国家游泳中心）\n",
            "毛主席纪念堂\n",
            "桃坪羌寨\n",
            "树正瀑布\n",
            "松潘古城\n",
            "恭王府\n",
            "居庸关长城\n",
            "天安门广场\n",
            "圆明园\n",
            "北海公园\n",
            "前门大街\n",
            "凤凰岭自然风景区\n",
            "八达岭长城\n",
            "什刹海\n",
            "人民英雄纪念碑\n",
            "人民大会堂\n",
            "五彩池\n",
            "争艳池\n",
            "九曲黄河第一湾\n",
            "中国国家博物馆"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fk1a8oxuEhZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "037b57c2-5f50-470c-e759-fb2ac0e3bc2b"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U coremltools"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting coremltools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/ab/b4dea5ab2503f3e601052958985153cd41bd4f9a336fb74f6789151d976e/coremltools-0.8-py3.5-none-manylinux1_x86_64.whl (2.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.5MB 8.2MB/s \n",
            "\u001b[?25hCollecting six==1.10.0 (from coremltools)\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b44607ab535be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (3.6.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->coremltools) (39.1.0)\n",
            "Installing collected packages: six, coremltools\n",
            "  Found existing installation: six 1.11.0\n",
            "    Uninstalling six-1.11.0:\n",
            "      Successfully uninstalled six-1.11.0\n",
            "Successfully installed coremltools-0.8 six-1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fIY2vRbwjLnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a3d97cb4-02e0-4ea3-85d8-e5afe54eb7f6"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model,load_model\n",
        "from keras.layers import Dense,GlobalAveragePooling2D,Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adadelta\n",
        "import keras\n",
        "import math, os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import coremltools\n",
        "\n",
        "\n",
        "\n",
        "def get_model():\n",
        "  \n",
        "    input_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
        "\n",
        "    # create the base pre-trained model\n",
        "    base_model = ResNet50(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
        "    \n",
        "    #base_model = ResNet50(input_tensor=None,weights='imagenet',include_top=False)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    updatedModel = Model(base_model.input, x)\n",
        "\n",
        "    return  updatedModel\n",
        "\n",
        "\n",
        "\n",
        "def compile_model(compiledModel):\n",
        "\n",
        "    compiledModel.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def modelFitGenerator(fitModel):\n",
        "\n",
        "    num_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
        "    num_valid_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
        "\n",
        "    num_train_steps = math.floor(num_train_samples/batch_size)\n",
        "    num_valid_steps = math.floor(num_valid_samples/batch_size)\n",
        "    \n",
        "    train_datagen = ImageDataGenerator(  \n",
        "      rotation_range=90,      \n",
        "      horizontal_flip=True,    \n",
        "      vertical_flip=True,\n",
        "      zoom_range=0.4)\n",
        "\n",
        "    test_datagen = ImageDataGenerator()\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical', shuffle=True\n",
        "    )\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "      validation_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical', shuffle=True\n",
        "    )\n",
        "\n",
        "    print(\"start history model\")\n",
        "    history = fitModel.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=num_train_steps,\n",
        "      epochs=nb_epoch,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=num_valid_steps)\n",
        "    \n",
        "    printGraph(history)\n",
        "\n",
        "def printGraph(history):\n",
        "    \n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "     \n",
        "    \n",
        "# def main():\n",
        "#     model = get_model()\n",
        "#     compile_model(model)\n",
        "#     modelFitGenerator(model)\n",
        "#     saveCoreMLModel(model)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # constants\n",
        "#     image_size = (224, 224)\n",
        "#     train_data_dir = 'drive/Resnet/landmark/train' \n",
        "#     validation_data_dir = 'drive/Resnet/landmark/test'\n",
        "#     nb_epoch = 50\n",
        "#     batch_size = 16\n",
        "#     num_classes = 2\n",
        "#     main()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:root:Keras version 2.1.6 detected. Last version known to be fully compatible of Keras is 2.1.3 .\n",
            "WARNING:root:TensorFlow version 1.10.1 detected. Last version known to be fully compatible is 1.5.0 .\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DoMZuvA39Lbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size = (224, 224)\n",
        "train_data_dir = 'drive/Resnet2/train' \n",
        "validation_data_dir = 'drive/Resnet2/test'\n",
        "nb_epoch = 50\n",
        "batch_size = 16\n",
        "num_classes = 23"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjV5n__69fpV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "compile_model(model)\n",
        "modelFitGenerator(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSnGmK1o9lYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3109
        },
        "outputId": "87b70e5e-fe0d-47e9-d88d-78ccf8e1be04"
      },
      "cell_type": "code",
      "source": [
        "def saveCoreMLModel(kerasModel):\n",
        "    coreml_model = coremltools.converters.keras.convert(kerasModel,\n",
        "                                                    input_names=['input'],\n",
        "                                                    output_names=['probs'],\n",
        "                                                    image_input_names='input',\n",
        "                                                    predicted_feature_name='predictedMoney',\n",
        "                                                    class_labels = 'drive/Resnet2/labels.txt')\n",
        "    coreml_model.save('resnet50custom.mlmodel') \n",
        "    print('CoreML model saved')\n",
        "    \n",
        "saveCoreMLModel(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : input_1, <keras.engine.topology.InputLayer object at 0x7f751a52c7b8>\n",
            "1 : conv1_pad, <keras.layers.convolutional.ZeroPadding2D object at 0x7f751a52c978>\n",
            "2 : conv1, <keras.layers.convolutional.Conv2D object at 0x7f751a52c390>\n",
            "3 : bn_conv1, <keras.layers.normalization.BatchNormalization object at 0x7f751a52cbe0>\n",
            "4 : activation_1, <keras.layers.core.Activation object at 0x7f751a52ce48>\n",
            "5 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x7f74fd27c860>\n",
            "6 : res2a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f751a5218d0>\n",
            "7 : bn2a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74fba29a20>\n",
            "8 : activation_2, <keras.layers.core.Activation object at 0x7f74fb106748>\n",
            "9 : res2a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74fb0a9d68>\n",
            "10 : bn2a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74fb0a9748>\n",
            "11 : activation_3, <keras.layers.core.Activation object at 0x7f74fb087b38>\n",
            "12 : res2a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74faf96f60>\n",
            "13 : res2a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f74faeeb128>\n",
            "14 : bn2a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74faf967b8>\n",
            "15 : bn2a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f751a52e198>\n",
            "16 : add_1, <keras.layers.merge.Add object at 0x7f75606c06a0>\n",
            "17 : activation_4, <keras.layers.core.Activation object at 0x7f74faecb828>\n",
            "18 : res2b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74faecbac8>\n",
            "19 : bn2b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74fad06898>\n",
            "20 : activation_5, <keras.layers.core.Activation object at 0x7f74facc5ba8>\n",
            "21 : res2b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74fabd2d68>\n",
            "22 : bn2b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74fabd2470>\n",
            "23 : activation_6, <keras.layers.core.Activation object at 0x7f74fabb5358>\n",
            "24 : res2b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74fab42630>\n",
            "25 : bn2b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74fab424e0>\n",
            "26 : add_2, <keras.layers.merge.Add object at 0x7f74fa918da0>\n",
            "27 : activation_7, <keras.layers.core.Activation object at 0x7f74fa940240>\n",
            "28 : res2c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74fa940198>\n",
            "29 : bn2c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74fa8f9710>\n",
            "30 : activation_8, <keras.layers.core.Activation object at 0x7f74fa899710>\n",
            "31 : res2c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74fa88a860>\n",
            "32 : bn2c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74fa8a4128>\n",
            "33 : activation_9, <keras.layers.core.Activation object at 0x7f74fa7e8c50>\n",
            "34 : res2c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74fa77ada0>\n",
            "35 : bn2c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74fa77a860>\n",
            "36 : add_3, <keras.layers.merge.Add object at 0x7f74fa6dc860>\n",
            "37 : activation_10, <keras.layers.core.Activation object at 0x7f74fa571588>\n",
            "38 : res3a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74fa571358>\n",
            "39 : bn3a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74fa514978>\n",
            "40 : activation_11, <keras.layers.core.Activation object at 0x7f74fa4d4ac8>\n",
            "41 : res3a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74fa4647b8>\n",
            "42 : bn3a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74fa464390>\n",
            "43 : activation_12, <keras.layers.core.Activation object at 0x7f74fa443668>\n",
            "44 : res3a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74fa35c550>\n",
            "45 : res3a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f74fa1a8c88>\n",
            "46 : bn3a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74fa35c400>\n",
            "47 : bn3a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f74fa14f160>\n",
            "48 : add_4, <keras.layers.merge.Add object at 0x7f74fa187c50>\n",
            "49 : activation_13, <keras.layers.core.Activation object at 0x7f74fa096080>\n",
            "50 : res3b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74fa096320>\n",
            "51 : bn3b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74fa0c0e80>\n",
            "52 : activation_14, <keras.layers.core.Activation object at 0x7f74fa07acc0>\n",
            "53 : res3b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f9f90da0>\n",
            "54 : bn3b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f9f90588>\n",
            "55 : activation_15, <keras.layers.core.Activation object at 0x7f74f9f72048>\n",
            "56 : res3b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f9e06748>\n",
            "57 : bn3b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f9e065f8>\n",
            "58 : add_5, <keras.layers.merge.Add object at 0x7f74f9cd50b8>\n",
            "59 : activation_16, <keras.layers.core.Activation object at 0x7f74f9cff358>\n",
            "60 : res3c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f9cff2b0>\n",
            "61 : bn3c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f9cb4828>\n",
            "62 : activation_17, <keras.layers.core.Activation object at 0x7f74f9c4a978>\n",
            "63 : res3c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f9bf2240>\n",
            "64 : bn3c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f9bf20f0>\n",
            "65 : activation_18, <keras.layers.core.Activation object at 0x7f74f9bca550>\n",
            "66 : res3c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f9a3aeb8>\n",
            "67 : bn3c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f9a3a978>\n",
            "68 : add_6, <keras.layers.merge.Add object at 0x7f74f9999da0>\n",
            "69 : activation_19, <keras.layers.core.Activation object at 0x7f74f992c128>\n",
            "70 : res3d_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f992c630>\n",
            "71 : bn3d_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f98d38d0>\n",
            "72 : activation_20, <keras.layers.core.Activation object at 0x7f74f990cbe0>\n",
            "73 : res3d_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f9722da0>\n",
            "74 : bn3d_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f97224a8>\n",
            "75 : activation_21, <keras.layers.core.Activation object at 0x7f74f9704358>\n",
            "76 : res3d_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f9615668>\n",
            "77 : bn3d_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f9615518>\n",
            "78 : add_7, <keras.layers.merge.Add object at 0x7f74f956a080>\n",
            "79 : activation_22, <keras.layers.core.Activation object at 0x7f74f9411278>\n",
            "80 : res4a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f94111d0>\n",
            "81 : bn4a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f9447748>\n",
            "82 : activation_23, <keras.layers.core.Activation object at 0x7f74f93e7748>\n",
            "83 : res4a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f9358898>\n",
            "84 : bn4a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f937f160>\n",
            "85 : activation_24, <keras.layers.core.Activation object at 0x7f74f93389b0>\n",
            "86 : res4a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f92c5fd0>\n",
            "87 : res4a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f74f922dd30>\n",
            "88 : bn4a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f92c5898>\n",
            "89 : bn4a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f74f91c0240>\n",
            "90 : add_8, <keras.layers.merge.Add object at 0x7f74f9022eb8>\n",
            "91 : activation_25, <keras.layers.core.Activation object at 0x7f74f8faf5c0>\n",
            "92 : res4b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f8faf780>\n",
            "93 : bn4b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f8f5b978>\n",
            "94 : activation_26, <keras.layers.core.Activation object at 0x7f74f8f17940>\n",
            "95 : res4b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f8ea8da0>\n",
            "96 : bn4b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f8ea8588>\n",
            "97 : activation_27, <keras.layers.core.Activation object at 0x7f74f8e833c8>\n",
            "98 : res4b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f8d9b748>\n",
            "99 : bn4b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f8d9b5f8>\n",
            "100 : add_9, <keras.layers.merge.Add object at 0x7f74f8bed0b8>\n",
            "101 : activation_28, <keras.layers.core.Activation object at 0x7f74f8b94358>\n",
            "102 : res4c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f8b942b0>\n",
            "103 : bn4c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f8bccf28>\n",
            "104 : activation_29, <keras.layers.core.Activation object at 0x7f74f8b6d4e0>\n",
            "105 : res4c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f8b075c0>\n",
            "106 : bn4c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f8b07470>\n",
            "107 : activation_30, <keras.layers.core.Activation object at 0x7f74f88d4d30>\n",
            "108 : res4c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f88fb278>\n",
            "109 : bn4c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f88fb128>\n",
            "110 : add_10, <keras.layers.merge.Add object at 0x7f74f88b6860>\n",
            "111 : activation_31, <keras.layers.core.Activation object at 0x7f74f883f4a8>\n",
            "112 : res4d_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f8804d68>\n",
            "113 : bn4d_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f883fe10>\n",
            "114 : activation_32, <keras.layers.core.Activation object at 0x7f74f87a3e10>\n",
            "115 : res4d_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f8734828>\n",
            "116 : bn4d_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f86dd048>\n",
            "117 : activation_33, <keras.layers.core.Activation object at 0x7f74f8694518>\n",
            "118 : res4d_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f8526d68>\n",
            "119 : bn4d_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f8526828>\n",
            "120 : add_11, <keras.layers.merge.Add object at 0x7f74f850b400>\n",
            "121 : activation_34, <keras.layers.core.Activation object at 0x7f74f841c550>\n",
            "122 : res4e_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f841c320>\n",
            "123 : bn4e_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f8442940>\n",
            "124 : activation_35, <keras.layers.core.Activation object at 0x7f74f84005f8>\n",
            "125 : res4e_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f8310b38>\n",
            "126 : bn4e_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f83106d8>\n",
            "127 : activation_36, <keras.layers.core.Activation object at 0x7f74f82f2ac8>\n",
            "128 : res4e_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f81827b8>\n",
            "129 : bn4e_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f8182748>\n",
            "130 : add_12, <keras.layers.merge.Add object at 0x7f74f80e1940>\n",
            "131 : activation_37, <keras.layers.core.Activation object at 0x7f74f8080278>\n",
            "132 : res4f_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f8080400>\n",
            "133 : bn4f_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f8019b38>\n",
            "134 : activation_38, <keras.layers.core.Activation object at 0x7f74f7fd84a8>\n",
            "135 : res4f_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f7e75710>\n",
            "136 : bn4f_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f7e755c0>\n",
            "137 : activation_39, <keras.layers.core.Activation object at 0x7f74f7dbd080>\n",
            "138 : res4f_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f7d653c8>\n",
            "139 : bn4f_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f7d65278>\n",
            "140 : add_13, <keras.layers.merge.Add object at 0x7f74f7d1b9b0>\n",
            "141 : activation_40, <keras.layers.core.Activation object at 0x7f74f7b55128>\n",
            "142 : res5a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f7b6d080>\n",
            "143 : bn5a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f7b55240>\n",
            "144 : activation_41, <keras.layers.core.Activation object at 0x7f74f7aa0978>\n",
            "145 : res5a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f7ac7240>\n",
            "146 : bn5a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f7ac70f0>\n",
            "147 : activation_42, <keras.layers.core.Activation object at 0x7f74f7a83668>\n",
            "148 : res5a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f798eeb8>\n",
            "149 : res5a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f74f7803a20>\n",
            "150 : bn5a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f798e978>\n",
            "151 : bn5a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f74f7803630>\n",
            "152 : add_14, <keras.layers.merge.Add object at 0x7f74f7977d30>\n",
            "153 : activation_43, <keras.layers.core.Activation object at 0x7f74f76fb668>\n",
            "154 : res5b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f76fb828>\n",
            "155 : bn5b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f76a0a20>\n",
            "156 : activation_44, <keras.layers.core.Activation object at 0x7f74f76609e8>\n",
            "157 : res5b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f75ee9e8>\n",
            "158 : bn5b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f75ee630>\n",
            "159 : activation_45, <keras.layers.core.Activation object at 0x7f74f7451160>\n",
            "160 : res5b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f73e07f0>\n",
            "161 : bn5b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f73e06a0>\n",
            "162 : add_15, <keras.layers.merge.Add object at 0x7f74f7336128>\n",
            "163 : activation_46, <keras.layers.core.Activation object at 0x7f74f72dc400>\n",
            "164 : res5c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f74f72dc358>\n",
            "165 : bn5c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f74f72958d0>\n",
            "166 : activation_47, <keras.layers.core.Activation object at 0x7f74f72b68d0>\n",
            "167 : res5c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f74f70d1668>\n",
            "168 : bn5c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f74f70d1518>\n",
            "169 : activation_48, <keras.layers.core.Activation object at 0x7f74f701d080>\n",
            "170 : res5c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f74f7045320>\n",
            "171 : bn5c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f74f70451d0>\n",
            "172 : add_16, <keras.layers.merge.Add object at 0x7f74f6f9d390>\n",
            "173 : activation_49, <keras.layers.core.Activation object at 0x7f74f6f8ba58>\n",
            "174 : avg_pool, <keras.layers.pooling.AveragePooling2D object at 0x7f74f6f8bf60>\n",
            "175 : global_average_pooling2d_1, <keras.layers.pooling.GlobalAveragePooling2D object at 0x7f74f6d7cfd0>\n",
            "176 : dense_1, <keras.layers.core.Dense object at 0x7f74f6eebef0>\n",
            "177 : dense_1__activation__, <keras.layers.core.Activation object at 0x7f74e5a9f438>\n",
            "CoreML model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e3tD9PfHxwS9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('resnet50custom.mlmodel') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GajFh5LaW8Rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "1a959226-48a5-4bbe-ea9e-d05d11e90a7c"
      },
      "cell_type": "code",
      "source": [
        "uploaded = drive.CreateFile()\n",
        "uploaded.SetContentFile('resnet50custom.mlmodel')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1BrwmyeBYqNC79CsugmiWzo1Y1d6ylr8Y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}